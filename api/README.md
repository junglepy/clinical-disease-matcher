# API сервер Clinical Disease Matcher

REST API сервис для сопоставления клинических диагнозов с кодами заболеваний OMIM/MONDO, использующий гибридный подход с BM25 поиском и LLM переранжированием.

## Архитектура

Сервис использует двухэтапный подход:
1. **BM25 поиск** - быстрый поиск кандидатов по базам OMIM/MONDO
2. **LLM переранжирование** - точный выбор лучшего результата с помощью LLM

## Быстрый старт

### Запуск через Docker (рекомендуется)

```bash
# Из папки api
docker build -t clinical-api .
docker run -p 8002:8002 --env-file .env clinical-api
```

### Локальный запуск

```bash
cd api
cp .env.example .env
# Отредактируйте .env - добавьте OPENAI_API_KEY

pip install -r requirements.txt
python main.py
```

## Конфигурация

### Переменные окружения (.env)

```env
# Обязательные
OPENAI_API_KEY=your-api-key-here

# Опциональные
OPENAI_MODEL=gpt-4-turbo-preview
LOG_LEVEL=INFO
PORT=8002
```

## API Endpoints

### 1. Проверка состояния

```http
GET /api/v1/health
```

Ответ:
```json
{
    "status": "healthy",
    "version": "1.0.0",
    "model": "gpt-4-turbo-preview",
    "databases": {
        "omim": 17506,
        "mondo": 23712
    }
}
```

### 2. Сопоставление одного диагноза

```http
POST /api/v1/match
Content-Type: application/json

{
    "text": "Синдром Марфана",
    "gene": "FBN1",
    "language": "ru"
}
```

Параметры:
- `text` (string, обязательный) - текст диагноза
- `gene` (string, опциональный) - символ гена для уточнения
- `language` (string, опциональный) - язык текста (ru/en), по умолчанию ru
- `full_context` (string, опциональный) - полный контекст строки из таблицы

Ответ:
```json
{
    "status": "success",
    "results": [
        {
            "omim_id": "OMIM:154700",
            "mondo_id": "MONDO:0007947",
            "name": "Marfan syndrome",
            "score": 0.95,
            "genes": ["FBN1"],
            "confidence": "high",
            "requires_clarification": false
        }
    ],
    "metadata": {
        "processing_time": 12.5,
        "candidates_found": 20,
        "reranked": true
    }
}
```

### 3. Пакетная обработка

```http
POST /api/v1/batch_match
Content-Type: multipart/form-data

file: <CSV или Excel файл>
```

Ответ: обработанный файл с добавленными колонками OMIM/MONDO кодов.

## Внутренняя архитектура

### Компоненты системы

1. **data_loader.py** - загрузка баз данных OMIM/MONDO
   - Фильтрация только записей заболеваний (не генов)
   - Загрузка синонимов и альтернативных названий
   - Кросс-ссылки между базами

2. **search_engine_bm25.py** - локальный BM25 поиск
   - Индексация названий заболеваний и синонимов
   - Поддержка множественных запросов
   - Дедупликация результатов

3. **llm_query_generator.py** - генерация запросов через LLM
   - Создание 3-5 вариантов запроса на английском
   - Учёт медицинской терминологии
   - Fallback на встроенный словарь

4. **gene_lookup.py** - работа с генами
   - Сопоставление генов с заболеваниями
   - Валидация консистентности ген-заболевание

5. **hybrid_orchestrator.py** - основная логика
   - Координация всех компонентов
   - Обработка запросов
   - Формирование ответов

6. **llm_reranker.py** - переранжирование через LLM
   - Анализ топ-20 кандидатов
   - Учёт контекста и генов
   - Выбор лучшего результата

### Промпты

Промпты для LLM находятся в директории `prompts/`:
- `reranking_prompt.txt` - основной промпт для выбора лучшего заболевания
- `query_generation_prompt.txt` - промпт для генерации вариантов запроса

## Производительность

- **Время ответа**: 10-20 секунд (зависит от LLM)
- **Точность**: ~91% для диагнозов с генами
- **Пропускная способность**: до 10 параллельных запросов

## Мониторинг и логи

### Уровни логирования

```python
# В .env
LOG_LEVEL=DEBUG  # DEBUG, INFO, WARNING, ERROR
```

### Формат логов

```
2024-01-15 10:23:45,123 - INFO - Processing diagnosis: Синдром Марфана
2024-01-15 10:23:46,234 - DEBUG - BM25 found 20 candidates
2024-01-15 10:23:58,345 - INFO - LLM selected: OMIM:154700 (Marfan syndrome)
```

## Разработка

### Структура кода

```
api/
├── src/
│   ├── __init__.py
│   ├── config.py           # Конфигурация
│   ├── data_loader.py      # Загрузка данных
│   ├── search_engine_bm25.py  # BM25 поиск
│   ├── llm_query_generator.py # Генерация запросов
│   ├── gene_lookup.py      # Работа с генами
│   ├── text_preprocessor.py   # Предобработка текста
│   ├── hybrid_orchestrator.py # Основная логика
│   └── llm_reranker.py     # LLM переранжирование
├── prompts/
│   ├── reranking_prompt.txt
│   └── query_generation_prompt.txt
├── datasets/               # Данные OMIM/MONDO
├── main.py                # FastAPI приложение
├── requirements.txt
├── Dockerfile
└── .env.example
```

### Добавление новых источников данных

1. Создайте новый загрузчик в `src/data_loader.py`
2. Добавьте индексацию в `src/search_engine_bm25.py`
3. Обновите логику в `src/hybrid_orchestrator.py`

### Улучшение промптов

Промпты можно редактировать без изменения кода:
1. Отредактируйте файл в `prompts/`
2. Перезапустите сервис или пересоберите Docker образ

## Известные ограничения

1. **Скорость**: LLM добавляет 10-15 секунд к времени обработки
2. **Стоимость**: Каждый запрос использует токены OpenAI API
3. **Язык**: Оптимизирован для русского языка, английский работает но менее точно
4. **Масштабируемость**: Ограничена лимитами OpenAI API

## Troubleshooting

### Ошибка "OPENAI_API_KEY not set"
Убедитесь, что в файле `.env` указан корректный API ключ.

### Долгое время ответа
- Проверьте интернет-соединение
- Убедитесь, что OpenAI API доступен
- Попробуйте уменьшить количество кандидатов в конфигурации

### Низкая точность
- Проверьте актуальность данных OMIM/MONDO
- Убедитесь, что используется правильная модель GPT-4
- Проверьте качество входных данных (опечатки, сокращения)

## Поддержка

При возникновении проблем:
1. Проверьте логи сервиса
2. Убедитесь в правильности конфигурации
3. Создайте issue в репозитории проекта